{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References \n",
    "The material and images presented here are with reference to the following sites: \n",
    "* [Reference1](http://www.admin-magazine.com/HPC/Articles/Parallel-Python-with-Joblib)\n",
    "* [joblib-examples](https://joblib.readthedocs.io/en/latest/auto_examples/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to make your computation Faster !! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "# Joblib\n",
    "\n",
    "* A set of tools to provide **lightweight pipelining in python**\n",
    "    * In particular\n",
    "        * transparent disk-caching \n",
    "        * embarrassingly parallel computing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "allows to: \n",
    "* easily parallel computations in python\n",
    "* avoid repetetive and costly computations\n",
    "* store intermediate results to warm start experience\n",
    "* have memory-map to an array stored on disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Embarrassingly parallel computing \n",
    "\n",
    "\n",
    "* One definition: \n",
    "\n",
    "```\n",
    "    Problems involving input objects that can be independently and concurrently processed are referred as Embarrassingly parallel\n",
    "    \n",
    "```\n",
    "* Example in our daily routine: **Gridsearch**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Parallel processing of task on multiple CPUs\n",
    "<img src=\"./images/job-F01_reference.jpg\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import time \n",
    "def f(x):\n",
    "    time.sleep(0.5)\n",
    "    return sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from math import sqrt\n",
    "from joblib import Parallel, delayed\n",
    "Parallel(n_jobs=-1)(delayed(f)(i) for i in range(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from math import sqrt\n",
    "[f(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>:\n",
    "\n",
    "<ul>\n",
    " <li> Compare the parallel processing using joblib and multiprocessing library by looking at <b>parallel_joblib.py</b> and <b>parallel_multiprocessing</b> \n",
    "  </li>\n",
    " <li> <b>Note:</b>  run the two process in terminal not in notebook </li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching: avoiding repetetive and costly computations\n",
    "* Joblibe provides a chache method that can be used as a decorator for a function with one ore more arguments\n",
    "* Using cache the results are saved on disk by the memory objects \n",
    "* This means: **If the results are already in the cache the function wont compute them again !!**\n",
    "\n",
    "* Memory cache of joblib\n",
    "<img src=\"./images/job-F02_reference.jpg\" alt=\"drawing\" width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def f(x):\n",
    "    time.sleep(0.5)\n",
    "    return sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Parallel(n_jobs=-1)(delayed(f)(i) for i in range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "<b>EXERCISE</b>:\n",
    "\n",
    "<ul>\n",
    " <li> Lets look at <b> memory_function.py</b> and run the script for better understanding of the memory function.</li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run memory_function.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing intermediate results\n",
    "* This information are inspired from this [example](https://joblib.readthedocs.io/en/latest/auto_examples/nested_parallel_memory.html#sphx-glr-auto-examples-nested-parallel-memory-py) in joblib library\n",
    "\n",
    "* Using `joblib.Memory` & `joblib.Parallel` we will cache intermediate results\n",
    "\n",
    "* Lets have a look at `nested_parallel_memory.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run nested_parallel_memory.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memmap\n",
    "* Looking at `joblib.Parallel` help we have these two parameters: \n",
    "\n",
    "```\n",
    "\n",
    "max_nbytes int, str, or None, optional, 1M by default\n",
    "      Threshold on the size of arrays passed to the workers that\n",
    "      triggers automated memory mapping in temp_folder. \n",
    "      Can be an int in Bytes, or a human-readable string, e.g., '1M' for 1 megabyte.\n",
    "      Use None to disable memmapping of large arrays.\n",
    "      Only active when backend=\"loky\" or \"multiprocessing\".\n",
    "    \n",
    "mmap_mode: {None, 'r+', 'r', 'w+', 'c'}\n",
    "       Memmapping mode for numpy arrays passed to workers.\n",
    "       See 'max_nbytes' parameter documentation for more details\n",
    " \n",
    "```\n",
    "\n",
    "* These ability is useful while dealing with large data or arrays. Which avoids copying the entire data for each processing and just reads the data from memory map located on the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run parallel_memmap.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
